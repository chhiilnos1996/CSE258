{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from below:\n",
    "# https://cseweb.ucsd.edu/classes/fa21/cse258-b/files/\n",
    "dataset = list(parse(\"trainRecipes.json.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:150000]\n",
    "valid = dataset[150000:175000]\n",
    "test = dataset[175000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'double delicious cookie bars',\n",
       " 'minutes': 40,\n",
       " 'contributor_id': '26865936',\n",
       " 'submitted': '2007-08-27',\n",
       " 'steps': 'preheat oven to 350f\\tin 13x9-inch baking pan , melt butter in oven\\tsprinkle crumbs evenly over butter\\tpour milk evenly over crumbs\\ttop with remaining ingredients\\tpress down firmly\\tbake 25-30 minutes or until lightly browned\\tcool completely , chill if desired , and cut into bars',\n",
       " 'description': 'from \"all time favorite recipes\". for fun, try substituting butterscotch or white chocolate chips for the semi-sweet and/or peanut butter chips. make sure you cool it completely or the bottom will crumble!',\n",
       " 'ingredients': ['butter',\n",
       "  'graham cracker crumbs',\n",
       "  'sweetened condensed milk',\n",
       "  'semi-sweet chocolate chips',\n",
       "  'peanut butter chips'],\n",
       " 'recipe_id': '98015212'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 8)\n",
      "(2018, 12)\n"
     ]
    }
   ],
   "source": [
    "import dateutil.parser\n",
    "year_list = [(dateutil.parser.parse(d['submitted']).year,dateutil.parser.parse(d['submitted']).month) for d in dataset]\n",
    "print(min(year_list)) ## 1999 Aug\n",
    "print(max(year_list)) ## 2018 Dec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salt', 'butter', 'sugar', 'onion', 'water', 'eggs', 'olive oil', 'flour', 'milk', 'garlic cloves', 'pepper', 'brown sugar', 'garlic', 'all-purpose flour', 'baking powder', 'egg', 'salt and pepper', 'parmesan cheese', 'lemon juice', 'baking soda', 'vegetable oil', 'vanilla', 'black pepper', 'cinnamon', 'tomatoes', 'sour cream', 'garlic powder', 'vanilla extract', 'oil', 'honey', 'garlic clove', 'cream cheese', 'onions', 'celery', 'cheddar cheese', 'unsalted butter', 'mayonnaise', 'soy sauce', 'chicken broth', 'paprika', 'extra virgin olive oil', 'worcestershire sauce', 'fresh parsley', 'cornstarch', 'fresh ground black pepper', 'parsley', 'carrots', 'chili powder', 'ground cinnamon', 'bacon']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "ingredients_list = []\n",
    "for d in dataset :\n",
    "    ingredients_list += d['ingredients']\n",
    "ingredients_count = Counter(ingredients_list)\n",
    "#print(ingredients_count)\n",
    "#print(ingredients_count.most_common(50))\n",
    "top_50_ingredients = [i[0] for i in ingredients_count.most_common(50)]\n",
    "print(top_50_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "<img src=\"question1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[743]\n"
     ]
    }
   ],
   "source": [
    "def feat1a(d):\n",
    "    return [len(d['steps'])]\n",
    "\n",
    "print(feat1a(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def feat1b(d): ## 1999 to 2018 -> 20 dimensional vector\n",
    "    year_feat = [0]*20\n",
    "    year_feat[dateutil.parser.parse(d['submitted']).year - 1999] = 1\n",
    "    month_feat = [0]*12\n",
    "    month_feat[dateutil.parser.parse(d['submitted']).month-1] = 1\n",
    "    return year_feat+month_feat\n",
    "\n",
    "print(feat1b(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def feat1c(d):\n",
    "    return [int(i in d['ingredients']) for i in top_50_ingredients]\n",
    "\n",
    "print(feat1c(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(d, a = True, b = True, c = True):\n",
    "    # Hint: for Questions 1 and 2, might be useful to set up a function like this\n",
    "    #       which allows you to \"select\" which features are included\n",
    "    feat = []\n",
    "    if a==True:\n",
    "        feat += feat1a(d)\n",
    "    if b==True:\n",
    "        feat += feat1b(d)\n",
    "    if c==True:\n",
    "        feat += feat1c(d)\n",
    "    return feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def MSE(y, ypred):\n",
    "    return np.square(y - ypred).mean(axis=0)\n",
    "    # Can use library if you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(a = True, b = True, c = True, mod= linear_model.LinearRegression()):\n",
    "    X_train = [feat(d, a, b, c) for d in train]\n",
    "    y_train = [d['minutes'] for d in train]\n",
    "    X_test = [feat(d, a, b, c) for d in test]\n",
    "    y_test = [d['minutes'] for d in test]\n",
    "    mod.fit(X_train, y_train)\n",
    "    ypred = model.predict(X_test)\n",
    "    mse = MSE(y_test, ypred)\n",
    "    print(mse)\n",
    "\n",
    "    # Hint: might be useful to write this function which extracts features and \n",
    "    #       computes the performance of a particular model on those features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 1:\n",
    "a. feat1a(dataset[0]) = [743]\n",
    "b. feat1b(dataset[0]) = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "c. feat1c(dataset[0]) = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "<img src=\"question2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5880.429911272418\n"
     ]
    }
   ],
   "source": [
    "# all features\n",
    "model = linear_model.LinearRegression()\n",
    "experiment(True, True, True, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5992.733953105812\n"
     ]
    }
   ],
   "source": [
    "# ablation feature 1a\n",
    "model = linear_model.LinearRegression()\n",
    "experiment(False, True, True, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5888.916117624437\n"
     ]
    }
   ],
   "source": [
    "# ablation feature 1b\n",
    "model = linear_model.LinearRegression()\n",
    "experiment(True, False, True, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6240.125264343656\n"
     ]
    }
   ],
   "source": [
    "# ablation feature 1c\n",
    "model = linear_model.LinearRegression()\n",
    "experiment(True, True, False, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 2:\n",
    "\n",
    "a. MSE on test ser for ablation feature 1a : 5992.733953105812\n",
    "\n",
    "b. MSE on test ser for ablation feature 1b : 5888.916117624437\n",
    "\n",
    "c. MSE on test ser for ablation feature 1c : 6240.125264343656\n",
    "\n",
    "d. feature 1c is most important cause MSE explodes the most when feature 1c is excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    for lamb in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "<img src=\"question4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 4:\n",
    "\n",
    "a. Since the most cooking time lie in 15-30 minutes, and only few (long tail) has 8+ hour range, the model may find it hard to predict the long tail data, and might have huge penalization on those 8+ hour recipes.\n",
    "\n",
    "b. Suggestion1 : I would try to replicate the data in tails so that the cooking time has more equal distribution.\n",
    "\n",
    "c. Suggestion2 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "<img src=\"question5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BER(predictions, y):\n",
    "    # Implement following this logic or otherwise\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "    FP = sum([(p and not(l)) for (p,l) in zip(predictions, y)])\n",
    "    TN = sum([(not(p) and not(l)) for (p,l) in zip(predictions, y)])\n",
    "    FN = sum([(not(p) and l) for (p,l) in zip(predictions, y)])\n",
    "    BER = 0.5 * (FN / (TP + FN) + FP / (TN + FP))\n",
    "    #print(TP, FP, TN, FN)\n",
    "    return BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat2(d, dict_size, mostPopularInd):\n",
    "    fIng = [0] * dict_size\n",
    "    for i in d['ingredients']:\n",
    "        if i == 'butter':\n",
    "            continue\n",
    "        if i in mostPopularInd:\n",
    "            #print(\"*\")\n",
    "            fIng[mostPopularInd[i]] = 1\n",
    "    return fIng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900098441634009 0.2894992495605814 0.28898437523315856\n"
     ]
    }
   ],
   "source": [
    "def experiment(reg = 1, dict_size = 50):\n",
    "    # Hint: run an experiment with a particular regularization strength, and a particular one-hot encoding size\n",
    "    # extract features...\n",
    "    # (etc.) \n",
    "    mostPopularInd = dict(zip([i[0] for i in ingredients_count.most_common(dict_size)], range(dict_size)))\n",
    "    #print(mostPopularInd)\n",
    "    X_train = [feat2(d, dict_size, mostPopularInd) for d in train]\n",
    "    y_train = [int('butter' in d['ingredients']) for d in train]\n",
    "\n",
    "    X_valid = [feat2(d, dict_size, mostPopularInd) for d in valid]\n",
    "    y_valid = [int('butter' in d['ingredients']) for d in valid]\n",
    "    \n",
    "    X_test = [feat2(d, dict_size, mostPopularInd) for d in test]\n",
    "    y_test = [int('butter' in d['ingredients']) for d in test]\n",
    "    \n",
    "    mod = linear_model.LogisticRegression(C=reg, class_weight='balanced', solver = 'lbfgs')\n",
    "    mod.fit(X_train, y_train)\n",
    "    \n",
    "    ypred_train = mod.predict(X_train)\n",
    "    ypred_valid = mod.predict(X_valid)\n",
    "    ypred_test = mod.predict(X_test)\n",
    "    \n",
    "    ber_train = BER(ypred_train, y_train)\n",
    "    ber_valid = BER(ypred_valid, y_valid)\n",
    "    ber_test = BER(ypred_test, y_test)\n",
    "    print(ber_train, ber_valid, ber_test)\n",
    "    # (etc.)\n",
    "\n",
    "experiment(reg = 1, dict_size = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 5:\n",
    "\n",
    "a. BER = 0.28898437523315856"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "<img src=\"question6.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 50\n",
      "0.29062441573723236 0.29064380312920035 0.28965326046777945\n",
      "0.01 100\n",
      "0.26406086145975616 0.2648462891599574 0.26650275754168856\n",
      "0.01 500\n",
      "0.22849675171583544 0.23055365206358197 0.2303930628502352\n",
      "1 50\n",
      "0.2900098441634009 0.2894992495605814 0.28898437523315856\n",
      "1 100\n",
      "0.2620917378493318 0.2645598522496887 0.266360126687606\n",
      "1 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22340670702116017 0.22516993055836515 0.22551948967394542\n",
      "100 50\n",
      "0.28992859694645495 0.289556389439567 0.28895820818270845\n",
      "100 100\n",
      "0.26214510583908995 0.2645598522496887 0.2662752658593643\n",
      "100 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2233441739959211 0.22504205944626504 0.22555910442106264\n"
     ]
    }
   ],
   "source": [
    "def pipeline():\n",
    "    for C in [0.01, 1, 100]:\n",
    "        for dsize in [50, 100, 500]:\n",
    "            print(C,dsize)\n",
    "            experiment(C, dsize)\n",
    "            # Example values, can pick any others...\n",
    "            \n",
    "pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 6:\n",
    "\n",
    "a. As above <img src=\"answer6.png\">\n",
    "\n",
    "b. Selected Model : C=100, dsize=500\n",
    "\n",
    "   test BER =  0.22555910442106264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7\n",
    "#(open ended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 (Recommender Systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "<img src=\"question8.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility data structures\n",
    "ingsPerItem = defaultdict(set)\n",
    "itemsPerIng = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    r = d['recipe_id']\n",
    "    for i in d['ingredients']:\n",
    "        ingsPerItem[r].add(i)\n",
    "        itemsPerIng[i].add(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.4166666666666667, '68523854'), (0.38461538461538464, '12679596'), (0.36363636363636365, '79675099'), (0.36363636363636365, '56301588'), (0.35714285714285715, '87359281')]\n"
     ]
    }
   ],
   "source": [
    "def mostSimilar8(i, N):\n",
    "    similarities = []\n",
    "    ings = ingsPerItem[i]\n",
    "    for i2 in ingsPerItem.keys():\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(ings, ingsPerItem[i2])\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]\n",
    "\n",
    "print(mostSimilar8('06432987',5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 8:\n",
    "\n",
    "a. Five most similar recipes to '06432987'\n",
    "\n",
    "Jaccard Similarity, recipe ID\n",
    "\n",
    "(0.4166666666666667, '68523854')\n",
    "\n",
    "(0.38461538461538464, '12679596')\n",
    "\n",
    "(0.36363636363636365, '79675099')\n",
    "\n",
    "(0.36363636363636365, '56301588')\n",
    "\n",
    "(0.35714285714285715, '87359281')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "<img src=\"question9.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.22315311514274808, 'salt'), (0.2056685424969639, 'flour'), (0.19100394157199166, 'eggs'), (0.17882420717656095, 'sugar'), (0.17040052045973944, 'milk')]\n"
     ]
    }
   ],
   "source": [
    "def mostSimilar9(i, N):\n",
    "    similarities = []\n",
    "    items = itemsPerIng[i]\n",
    "    for i2 in itemsPerIng.keys():\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(items, itemsPerIng[i2])\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]\n",
    "\n",
    "print(mostSimilar9('butter',5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Question 9:\n",
    "\n",
    "a. Five most similar ingredients to 'butter'\n",
    "\n",
    "Jaccard Similarity, Ingredient\n",
    "\n",
    "(0.22315311514274808, 'salt')\n",
    "\n",
    "(0.2056685424969639, 'flour')\n",
    "\n",
    "(0.19100394157199166, 'eggs')\n",
    "\n",
    "(0.17882420717656095, 'sugar')\n",
    "\n",
    "(0.17040052045973944, 'milk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "<img src=\"question10.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x9/xv9fr3td34x85pl4rz2hy7kh0000gn/T/ipykernel_32160/1268084660.py:13: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  ing_list = random.sample(itemsPerIng.keys(),N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend recipes using ingredients: \n",
      "['rib eye steak', 'caesar salad dressing mix', 'dry linguine', 'wine-cured sauerkraut', 'cilantro chutney']\n",
      "\n",
      "sim =  0.1111111111111111 , recipe_id =  07037811\n",
      "{'dry white wine', 'lemon juice', 'olive oil', 'caesar salad dressing mix', 'salmon steaks'}\n",
      "sim =  0.1111111111111111 , recipe_id =  02190119\n",
      "{'cheez whiz', 'onion', 'rib eye steak', 'butter', 'hoagie rolls'}\n",
      "sim =  0.09090909090909091 , recipe_id =  73315294\n",
      "{'sour cream', 'milk', 'caesar salad dressing mix', 'italian cut green beans', 'italian style breadcrumbs', 'cheese ravioli', 'cream of mushroom soup'}\n",
      "sim =  0.09090909090909091 , recipe_id =  35328315\n",
      "{'wine-cured sauerkraut', 'honey mustard', 'apple', 'apple juice', 'potatoes', 'caraway seed', 'lean pork'}\n",
      "sim =  0.09090909090909091 , recipe_id =  30688537\n",
      "{'low-fat creme fraiche', 'baby spinach', 'dry linguine', 'smoked haddock', 'lemon, zest of', 'small capers', 'cherry tomatoes'}\n",
      "\n",
      "\n",
      "recommend recipes using ingredients: \n",
      "['whole grain oat flour', 'frangelico', 'strip steaks', 'powdered basil', 'nutmeg']\n",
      "\n",
      "sim =  0.25 , recipe_id =  35986508\n",
      "{'vodka', 'nutmeg', 'frangelico', 'dark creme de cacao', 'baileys irish cream'}\n",
      "sim =  0.16666666666666666 , recipe_id =  93603791\n",
      "{'southern comfort', 'frangelico'}\n",
      "sim =  0.16666666666666666 , recipe_id =  69775521\n",
      "{'milk', 'frangelico'}\n",
      "sim =  0.16666666666666666 , recipe_id =  29786183\n",
      "{'vanilla ice cream', 'frangelico'}\n",
      "sim =  0.16666666666666666 , recipe_id =  10278714\n",
      "{'eggnog', 'frangelico'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simply Jaccard\n",
    "def rec_recipe(ing_list,N): \n",
    "    similarities = []\n",
    "    for i2 in ingsPerItem.keys():\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(set(ing_list), ingsPerItem[i2])\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]\n",
    "\n",
    "def random_ing(N):\n",
    "    ing_list = random.sample(itemsPerIng.keys(),N)\n",
    "    print(\"recommend recipes using ingredients: \")\n",
    "    print(ing_list)\n",
    "    print()\n",
    "    return ing_list\n",
    "    \n",
    "def list_rec_recipe(M, N):\n",
    "    rec_recipes =  rec_recipe(random_ing(5),5)\n",
    "    for sim , recipe_id in rec_recipes: \n",
    "        print(\"sim = \", sim , \", recipe_id = \", recipe_id)\n",
    "        print(ingsPerItem[recipe_id])\n",
    "    print()\n",
    "    print()\n",
    "        \n",
    "list_rec_recipe(10,5)\n",
    "list_rec_recipe(6,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More creative system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer for Question 10:\n",
    "\n",
    "a. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
